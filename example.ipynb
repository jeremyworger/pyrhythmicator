{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyrhythmicator\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the rhythm synthesizer with 3 voices in 4/4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pg = pyrhythmicator.PatternGenerator(4,4,['4n','8n','16n',],\n",
    "                                     metric_factor=[1.,1.,1.,],\n",
    "                                     syncopate_factor=[0.,1.,1.,],\n",
    "                                     density=[0.5,0.5,0.9],\n",
    "                                     dynamic_range_low=[0.8,0.7,0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a 3-voice pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default `self.event_var`\n",
      "Using default `self.sync_var`\n",
      "Using default `self.threshold`\n",
      "Using default `self.weight_minimum`\n",
      "Using default `self.dynamic_range_high`\n"
     ]
    }
   ],
   "source": [
    "pg.generate_pattern(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize the pattern given the 3 audio files in `tests/data`. Output the audio to `output_file.wav` and the annotation file to `output_file.jams`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'instancemethod' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6191ca62ded5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m mix, voices = pg.synthesize('output_file.wav', \n\u001b[1;32m      2\u001b[0m                             \u001b[0moutput_jams_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_file.jams'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             audio_files=pyrhythmicator.list_audio_files_in_dir('tests/data', prepend_path=True))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mcartwright/git/pyrhythmicator/pyrhythmicator/core.pyc\u001b[0m in \u001b[0;36msynthesize\u001b[0;34m(self, output_file, **kwargs)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m             \u001b[0;31m# render samples at onsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m                 \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                 \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmixed_rhythm_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'instancemethod' has no len()"
     ]
    }
   ],
   "source": [
    "mix, voices = pg.synthesize('output_file.wav', \n",
    "                            output_jams_file='output_file.jams',\n",
    "                            audio_files=pyrhythmicator.list_audio_files_in_dir('tests/data', prepend_path=True))\n",
    "\n",
    "print('Mix:')\n",
    "display(Audio(mix, rate=pg.sample_rate))\n",
    "for k, voice in enumerate(voices):\n",
    "    print('Voice {}:'.format(k))\n",
    "    display(Audio(voice, rate=pg.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/mcartwright/git/pyrhythmicator/pyrhythmicator/core.py\u001b[0m(1618)\u001b[0;36msynthesize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1616 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1617 \u001b[0;31m            \u001b[0;31m# render samples at onsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1618 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1619 \u001b[0;31m                \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1620 \u001b[0;31m                \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmixed_rhythm_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> type(onset_ann.data)\n",
      "<class 'sortedcontainers.sortedlist.SortedListWithKey'>\n",
      "ipdb> onset_ann.data.__dict__\n",
      "{'_half': 500, '_offset': 0, '_index': [], '_len': 1, '_twice': 2000, '_key': <bound method type._key of <class 'jams.core.Annotation'>>, '_keys': [[0.0]], '_maxes': [0.0], '_lists': [[Observation(time=0.0, duration=0.0, value=0.75857757502918322, confidence=None)]], '_load': 1000}\n",
      "ipdb> onset_ann.data.len\n",
      "*** AttributeError: 'SortedListWithKey' object has no attribute 'len'\n",
      "ipdb> len(onset_ann.data)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize another output file, this time with a duration of 9.7 s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mix, voices = pg.synthesize('output_file2.wav', \n",
    "                            output_jams_file='output_file2.jams',\n",
    "                            duration_sec=9.7,\n",
    "                            audio_files=pyrhythmicator.list_audio_files_in_dir('tests/data', prepend_path=True))\n",
    "\n",
    "display(Audio(mix, rate=pg.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pattern generator and pattern from an annotation file, and synthesize again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = pyrhythmicator.PatternGenerator.from_jams('output_file2.jams')\n",
    "mix, voices = pg.synthesize('output_file3.wav')\n",
    "\n",
    "display(Audio(mix, rate=pg.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 5 patterns given the current pattern generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(5):\n",
    "    idx = random.randint(0,1000)\n",
    "    pg.generate_pattern(3)\n",
    "    mix, voices = pg.synthesize('pattern_{}.wav'.format(idx),\n",
    "                                output_jams_file='pattern_{}.jams'.format(idx),\n",
    "                                duration_sec=20.4,\n",
    "                                audio_files=pyrhythmicator.list_audio_files_in_dir('tests/data',prepend_path=True))\n",
    "    \n",
    "    print('Pattern {}:'.format(i))\n",
    "    display(Audio(mix, rate=pg.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
